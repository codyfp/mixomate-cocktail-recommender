{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Food.com Dataset Reccomender Binary Matrix\n",
    "Below is data exploration on the foolwoing dataset https://www.kaggle.com/datasets/shuyangli94/food-com-recipes-and-user-interactions?select=RAW_recipes.csv \n",
    "\n",
    "This dataset consists of 180K+ recipes and 700K+ recipe reviews covering 18 years of user interactions and uploads on Food.com "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import zipfile\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "#from surprise import SVD\n",
    "#from surprise import Dataset\n",
    "#from surprise import Reader\n",
    "#from surprise.model_selection import train_test_split\n",
    "#from surprise import accuracy\n",
    "#import tensorflow.keras as tf\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n",
    "From the zipped dataset we extract the recipes and the interactions (reviews).\n",
    "Below is how we got the data from the original very large dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip_file_path = \"archive.zip\"\n",
    "# csv_file_name1 = 'RAW_recipes.csv'\n",
    "# csv_file_name2 = 'RAW_interactions.csv' \n",
    "\n",
    "# # Initialize two DataFrames to store the data from the two CSV files\n",
    "# df1 = None\n",
    "# df2 = None\n",
    "\n",
    "# # Open the zip file and read the first CSV file into the first DataFrame\n",
    "# with zipfile.ZipFile(zip_file_path, 'r') as zip_file:\n",
    "#     with zip_file.open(csv_file_name1) as csv_file_in_zip:\n",
    "#         df_recipes = pd.read_csv(csv_file_in_zip)\n",
    "\n",
    "# # Open the zip file again and read the second CSV file into the second DataFrame\n",
    "# with zipfile.ZipFile(zip_file_path, 'r') as zip_file:\n",
    "#     with zip_file.open(csv_file_name2) as csv_file_in_zip:\n",
    "#         df_reviews = pd.read_csv(csv_file_in_zip)\n",
    "\n",
    "# #We renamed the id column to match to id in reviews so we can merge on this later\n",
    "# df_recipes.rename(columns={'id': 'recipe_id'}, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #We combine both the dataframes\n",
    "\n",
    "# combined_df = pd.merge(df_reviews, df_recipes, on='recipe_id', how='inner')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection\n",
    "\n",
    "Below we search the tags that indicate the recipe is for a cocktail. This cuts downs are dataset from 180K recipes to around 4K, significiantly reducing our file size. We have used this exported csv as our base dataset so we don't have to rely on git lfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df = combined_df[combined_df['tags'].str.contains('cocktails', case=False, na=False)]\n",
    "\n",
    "# combined_df.rename(columns={'id': 'recipe_id'}, inplace=True)\n",
    "\n",
    "# #We drop columns that we don't need\n",
    "# columns_to_drop = ['date', 'review','minutes','nutrition','contributor_id', 'description','submitted']\n",
    "\n",
    "# combined_df = combined_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# combined_df.to_csv(\"cocktail_dataset.csv\")\n",
    "# #Exporting a refined dataset to be used in mongoDB\n",
    "\n",
    "# to_keep = ['recipe_id','rating','name','n_steps','ingredients','steps','n_ingredients']\n",
    "\n",
    "# mongo_csv = combined_df[to_keep].drop_duplicates(subset=['name'])\n",
    "\n",
    "\n",
    "# mongo_csv.to_csv(\"cocktail_data_mongo.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "We are exploring the cocktail counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df = pd.read_csv(\"cocktail_dataset.csv\")\n",
    "\n",
    "# cocktail_review_counts = combined_df.groupby('recipe_id')['rating'].count().reset_index()\n",
    "# cocktail_review_counts.columns = ['recipe_id', 'review_count']\n",
    "# # Sort the DataFrame by review_count in descending order\n",
    "# # Sort the review counts DataFrame by review_count in descending order\n",
    "# cocktail_review_counts_sorted = cocktail_review_counts.sort_values(by='review_count', ascending=False)\n",
    "\n",
    "# # Merge the review counts DataFrame with the recipes DataFrame to get cocktail names\n",
    "# table_data = cocktail_review_counts_sorted.merge(df_recipes[['recipe_id', 'name']], on='recipe_id', how='inner')\n",
    "\n",
    "# # Display the table\n",
    "# table = tabulate(table_data, headers=['Recipe ID','Review Count','Cocktail Name'], tablefmt='pretty', showindex=False)\n",
    "# print(table)\n",
    "\n",
    "# print(cocktail_review_counts_sorted['review_count'].mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation for Matrix\n",
    "\n",
    "We Strip the regex characters from the ingredients column.\n",
    "\n",
    "We also need to remove the duplicates since one cocktail can have many reviews, and since we combined the reviews and coctail dataframes, there will be duplicates.\n",
    "\n",
    "The duplicates were useful for data exploration, but now exploration is done we need only unique values of the cocktails for our prediction matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only process if the first item in 'ingredients' column is a string\n",
    "if isinstance(combined_df['ingredients'].iloc[0], str):\n",
    "    # Remove [ and ] \n",
    "    combined_df['ingredients'] = combined_df['ingredients'].str.replace('[', '').str.replace(']', '')\n",
    "    # Splitting the ingredients string by commas\n",
    "    combined_df['ingredients'] = combined_df['ingredients'].str.split(',')\n",
    "\n",
    "\n",
    "# Drop duplicates based on the 'name' column and assign the result back to combined_df\n",
    "combined_df = combined_df.drop_duplicates(subset=['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if there are any duplicates before processing for the matrix\n",
    "\n",
    "duplicate_names = combined_df[combined_df['name'].duplicated(keep=False)]\n",
    "print(duplicate_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the 'ingredients' column\n",
    "exploded_df = combined_df.explode('ingredients')\n",
    "\n",
    "# Find unique ingredients\n",
    "unique_ingredients = exploded_df['ingredients'].unique()\n",
    "\n",
    "ingredient_counts = exploded_df['ingredients'].value_counts()\n",
    "\n",
    "exploded_df['ingredients'] = exploded_df['ingredients'].str.replace('','')\n",
    "\n",
    "print(ingredient_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cocktail Similarity\n",
    "## Next We will prepare the features of the data\n",
    "**Feature Extraction**\n",
    "The ingredients list will be the primary feature for our content-based filtering.\n",
    "**One-hot encoding**\n",
    "This converts our categorical data into a numerical format that machine learning algorithms can understand and process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the binarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Filtering out non-iterable items\n",
    "filtered_ingredients = [ingredients if isinstance(ingredients, (list, tuple)) else [] for ingredients in combined_df['ingredients']]\n",
    "\n",
    "# Apply MultiLabelBinarizer on the filtered data\n",
    "binary_matrix = mlb.fit_transform(filtered_ingredients)\n",
    "\n",
    "# Convert the binary matrix into a DataFrame for better visualization and manipulation\n",
    "df_binary = pd.DataFrame(binary_matrix, columns=mlb.classes_)\n",
    "\n",
    "\n",
    "combined_df = pd.concat([combined_df, df_binary], axis=1)\n",
    "\n",
    "combined_df = combined_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = cosine_similarity(df_binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_cocktails(input_value, N=5):\n",
    "    \"\"\"\n",
    "    Fetch similar cocktails based on a given cocktail name or ID.\n",
    "    \n",
    "    Args:\n",
    "    - input_value (str or int): Name or ID of the cocktail.\n",
    "    - N (int): Number of similar cocktails to return. Default is 5.\n",
    "\n",
    "    Returns:\n",
    "    - list: Names of top N similar cocktails.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Determine if input is name or ID\n",
    "    if isinstance(input_value, str):\n",
    "        if input_value not in combined_df['name'].values:\n",
    "            raise ValueError(f\"No cocktail named {input_value} found in the dataset.\")\n",
    "        cocktail_index = combined_df[combined_df['name'] == input_value].index[0]\n",
    "    elif isinstance(input_value, int):  # Assuming ID is an integer\n",
    "        if input_value not in combined_df['recipe_id'].values:\n",
    "            raise ValueError(f\"No cocktail with ID {input_value} found in the dataset.\")\n",
    "        cocktail_index = combined_df[combined_df['recipe_id'] == input_value].index[0]\n",
    "    else:\n",
    "        raise ValueError(\"Input value must be either a name (string) or an ID (integer).\")\n",
    "    \n",
    "    # Fetch and enumerate similarity scores for the given cocktail\n",
    "    similar_scores = list(enumerate(similarity_matrix[cocktail_index]))\n",
    "    \n",
    "    # Sort the scores\n",
    "    sorted_similar_scores = sorted(similar_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return the top N cocktail names excluding the input cocktail itself\n",
    "    return [combined_df.iloc[i[0]]['name'] for i in sorted_similar_scores[1:N+1]]\n",
    "\n",
    "get_similar_cocktails(98221)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping\n",
    "\n",
    "The provided code demonstrates an automated process for extracting the first image from Google Image search results based on a list of cocktail-related queries.\n",
    "\n",
    "---\n",
    "\n",
    "### Libraries and Initialization:\n",
    "\n",
    "**Selenium** is used for web automation. It opens a Chrome browser and interacts with web pages.  \n",
    "**Requests** and **io** libraries facilitate the downloading of images from the internet.  \n",
    "**PIL** from the Pillow library aids in image manipulation.\n",
    "\n",
    "---\n",
    "\n",
    "### Main Functions:\n",
    "\n",
    "**1. `get_first_image_from_google`:**  \n",
    "This function searches Google Images with a given query.  \n",
    "It clicks on the first image thumbnail to view it in full.  \n",
    "The direct URL of the image is then extracted and returned.\n",
    "\n",
    "**2. `download_image`:**  \n",
    "Given an image URL, this function fetches the image using the requests library.  \n",
    "The image is then saved to the local disk using the Pillow library.\n",
    "\n",
    "---\n",
    "\n",
    "### Execution:\n",
    "\n",
    "**Queries Creation:**  \n",
    "The code prepares a list of queries named `queries`, where each query is generated by appending \"food.com cocktail\" to each 'name' from the `combined_df` DataFrame.\n",
    "\n",
    "**Image Extraction:**  \n",
    "The code demonstrates two potential methods:  \n",
    "- Looping through the entire list of queries to download images for each one.\n",
    "- Looping through a limited number (e.g., first 5) of queries from the list.\n",
    "\n",
    "In this script, the second method is active. The code performs an image search for the first n cocktails from the list, fetches their first images, and saves them with a numerical filename (0.jpg, 1.jpg, etc.).\n",
    "\n",
    "After all operations, the automated browser session (`wd`) is closed using `wd.quit()`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\samue\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\common\\service.py:72\u001b[0m, in \u001b[0;36mService.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     71\u001b[0m     cmd\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_line_args())\n\u001b[1;32m---> 72\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39mPopen(cmd, env\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv,\n\u001b[0;32m     73\u001b[0m                                     close_fds\u001b[39m=\u001b[39mplatform\u001b[39m.\u001b[39msystem() \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mWindows\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     74\u001b[0m                                     stdout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_file,\n\u001b[0;32m     75\u001b[0m                                     stderr\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_file,\n\u001b[0;32m     76\u001b[0m                                     stdin\u001b[39m=\u001b[39mPIPE)\n\u001b[0;32m     77\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\samue\\anaconda3\\Lib\\subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1023\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[0;32m   1024\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m-> 1026\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m   1027\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m   1028\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m   1029\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m   1030\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m   1031\u001b[0m                         errread, errwrite,\n\u001b[0;32m   1032\u001b[0m                         restore_signals,\n\u001b[0;32m   1033\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m   1034\u001b[0m                         start_new_session, process_group)\n\u001b[0;32m   1035\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\samue\\anaconda3\\Lib\\subprocess.py:1538\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1537\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1538\u001b[0m     hp, ht, pid, tid \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39mCreateProcess(executable, args,\n\u001b[0;32m   1539\u001b[0m                              \u001b[39m# no special security\u001b[39;00m\n\u001b[0;32m   1540\u001b[0m                              \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1541\u001b[0m                              \u001b[39mint\u001b[39m(\u001b[39mnot\u001b[39;00m close_fds),\n\u001b[0;32m   1542\u001b[0m                              creationflags,\n\u001b[0;32m   1543\u001b[0m                              env,\n\u001b[0;32m   1544\u001b[0m                              cwd,\n\u001b[0;32m   1545\u001b[0m                              startupinfo)\n\u001b[0;32m   1546\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1547\u001b[0m     \u001b[39m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[39m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[39m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m     \u001b[39m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\samue\\OneDrive\\Documents\\GitHub\\software-innovation-studio\\modelGeneration\\New Dataset.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive/Documents/GitHub/software-innovation-studio/modelGeneration/New%20Dataset.ipynb#X24sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# For now use local path until I add relative path\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive/Documents/GitHub/software-innovation-studio/modelGeneration/New%20Dataset.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m PATH \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39msamue\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mOneDrive\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDocuments\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mGitHub\u001b[39m\u001b[39m\\\u001b[39m\u001b[39msoftware-innovation-studio\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mmodelGeneration\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mchromedriver.exe\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive/Documents/GitHub/software-innovation-studio/modelGeneration/New%20Dataset.ipynb#X24sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m wd \u001b[39m=\u001b[39m webdriver\u001b[39m.\u001b[39mChrome(PATH)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive/Documents/GitHub/software-innovation-studio/modelGeneration/New%20Dataset.ipynb#X24sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_first_image_from_google\u001b[39m(wd, query):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive/Documents/GitHub/software-innovation-studio/modelGeneration/New%20Dataset.ipynb#X24sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m# Format the URL with the given query\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive/Documents/GitHub/software-innovation-studio/modelGeneration/New%20Dataset.ipynb#X24sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://www.google.com/search?q=\u001b[39m\u001b[39m{\u001b[39;00mquery\u001b[39m}\u001b[39;00m\u001b[39m&tbm=isch\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\samue\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py:73\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[1;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, keep_alive)\u001b[0m\n\u001b[0;32m     66\u001b[0m         desired_capabilities\u001b[39m.\u001b[39mupdate(options\u001b[39m.\u001b[39mto_capabilities())\n\u001b[0;32m     68\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice \u001b[39m=\u001b[39m Service(\n\u001b[0;32m     69\u001b[0m     executable_path,\n\u001b[0;32m     70\u001b[0m     port\u001b[39m=\u001b[39mport,\n\u001b[0;32m     71\u001b[0m     service_args\u001b[39m=\u001b[39mservice_args,\n\u001b[0;32m     72\u001b[0m     log_path\u001b[39m=\u001b[39mservice_log_path)\n\u001b[1;32m---> 73\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice\u001b[39m.\u001b[39mstart()\n\u001b[0;32m     75\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m     RemoteWebDriver\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[0;32m     77\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m     78\u001b[0m         command_executor\u001b[39m=\u001b[39mChromeRemoteConnection(\n\u001b[0;32m     79\u001b[0m             remote_server_addr\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice\u001b[39m.\u001b[39mservice_url,\n\u001b[0;32m     80\u001b[0m             keep_alive\u001b[39m=\u001b[39mkeep_alive),\n\u001b[0;32m     81\u001b[0m         desired_capabilities\u001b[39m=\u001b[39mdesired_capabilities)\n",
      "File \u001b[1;32mc:\\Users\\samue\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\common\\service.py:81\u001b[0m, in \u001b[0;36mService.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m     80\u001b[0m     \u001b[39mif\u001b[39;00m err\u001b[39m.\u001b[39merrno \u001b[39m==\u001b[39m errno\u001b[39m.\u001b[39mENOENT:\n\u001b[1;32m---> 81\u001b[0m         \u001b[39mraise\u001b[39;00m WebDriverException(\n\u001b[0;32m     82\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m executable needs to be in PATH. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\n\u001b[0;32m     83\u001b[0m                 os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart_error_message)\n\u001b[0;32m     84\u001b[0m         )\n\u001b[0;32m     85\u001b[0m     \u001b[39melif\u001b[39;00m err\u001b[39m.\u001b[39merrno \u001b[39m==\u001b[39m errno\u001b[39m.\u001b[39mEACCES:\n\u001b[0;32m     86\u001b[0m         \u001b[39mraise\u001b[39;00m WebDriverException(\n\u001b[0;32m     87\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m executable may have wrong permissions. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\n\u001b[0;32m     88\u001b[0m                 os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart_error_message)\n\u001b[0;32m     89\u001b[0m         )\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import io\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "\n",
    "# See README for setup of chromedriver\n",
    "\n",
    "PATH = r\"C:\\Users\\samue\\OneDrive\\Documents\\GitHub\\software-innovation-studio\\modelGeneration\\chromedriver.exe\"\n",
    "wd = webdriver.Chrome(PATH)\n",
    "\n",
    "def get_first_image_from_google(wd, query):\n",
    "    # Format the URL with the given query\n",
    "    url = f\"https://www.google.com/search?q={query}&tbm=isch\"\n",
    "    wd.get(url)\n",
    "    \n",
    "    try:\n",
    "        # Find the first image thumbnail and click it\n",
    "        thumbnail = wd.find_element(By.CLASS_NAME, \"Q4LuWd\")\n",
    "        thumbnail.click()\n",
    "        time.sleep(1)  # Wait for the image to load\n",
    "\n",
    "        # Extract the image URL\n",
    "        image = wd.find_element(By.CLASS_NAME, \"r48jcc\")\n",
    "        if image.get_attribute('src') and 'http' in image.get_attribute('src'):\n",
    "            return image.get_attribute('src')\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    return None\n",
    "\n",
    "def download_image(download_path, url, file_name):\n",
    "    try:\n",
    "        image_content = requests.get(url).content\n",
    "        image_file = io.BytesIO(image_content)\n",
    "        image = Image.open(image_file)\n",
    "        file_path = download_path + file_name\n",
    "\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            image.save(f, \"JPEG\")\n",
    "\n",
    "        print(\"Success\")\n",
    "    except Exception as e:\n",
    "        print('FAILED -', e)\n",
    "\n",
    "queries = [f\"{row['name']} food.com cocktail\" for _, row in combined_df.iterrows()]\n",
    "\n",
    "# This Loops through entire dataset of cocktails\n",
    "# for i in range(len(queries)):\n",
    "#     url = get_first_image_from_google(wd, queries[i])\n",
    "#     if url:\n",
    "#         download_image(\"\", url, f\"{i}.jpg\")\n",
    "\n",
    "#Just does n amount\n",
    "n = 5\n",
    "for i in range(n):\n",
    "    url = get_first_image_from_google(wd, queries[i])\n",
    "    if url:\n",
    "        download_image(\"\", url, f\"{i}.jpg\")\n",
    "\n",
    "\n",
    "wd.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
